{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script do:\n",
    "- preprocess:\n",
    "    - reset time zone to Asia/Shanghei \n",
    "    -\n",
    "- add features\n",
    "   - mean encode \n",
    "       - by (ip,app,device,os)\n",
    "    \n",
    "- features base\n",
    "    - use only (gain importance)\n",
    "        - app_mean_target\n",
    "        - app\n",
    "        - channel_mean_target\n",
    "        - next_click_dt\n",
    "        - channel_nunique_ip\n",
    "        - os\n",
    "        - channel\n",
    "        - hour\n",
    "        - app_nunique_channel\n",
    "        - channel_cnt_ip_app\n",
    "        - hour_nunique_day_ip\n",
    "        - app_nunique_ip\n",
    "        - app_nunique_ip_device_os\n",
    "        - device_mean_target \t\n",
    "        - channel_cnt_ip_day_hour\n",
    "        - app_cumcnt_ip_device_os\n",
    "        - ip_mean_target\n",
    "        - os_mean_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pytz\n",
    "%matplotlib inline \n",
    "import gc,time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/test_df', '/train_df']\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('../input/raw_data.h5') as store:\n",
    "    print(store.keys())\n",
    "    test_df = store['test_df']\n",
    "    train_df = store['train_df']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (train_df.day>7) & (train_df.day<10)\n",
    "trn_df = train_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_trn = len(trn_df)\n",
    "trn_df = trn_df.append(test_df)\n",
    "\n",
    "del train_df;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_df :(143984060, 10)\n"
     ]
    }
   ],
   "source": [
    "print('trn_df :{}'.format(trn_df.shape)) # \n",
    "# print('test_df:{}'.format(test_df.shape))\n",
    "del test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- len_trn  : 125193591 \n",
    "\n",
    "- len_tst  : 18790469"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_agg_feature(train_df, selcols, groupby, aggregator = 'nunique'):\n",
    "    usecols = [e for e in selcols if e not in  groupby]    \n",
    "    \n",
    "    if aggregator == 'nunique':  \n",
    "        colname= usecols[-1] + '_nunique_' + '_'.join(groupby)\n",
    "        if colname in train_df.columns:\n",
    "            train_df.drop(colname,axis=1,inplace=True)\n",
    "            \n",
    "        gp = train_df[selcols].groupby(groupby)[usecols].nunique().reset_index().\\\n",
    "            rename(columns = {\n",
    "                usecols[-1] : usecols[-1] + '_nunique_' + '_'.join(groupby)\n",
    "            })\n",
    "        train_df = train_df.merge(gp, how='left', on=groupby)\n",
    "\n",
    "    elif aggregator == 'cumcount':\n",
    "        colname = usecols[-1] + '_cumcnt_' + '_'.join(groupby)\n",
    "        if colname in train_df.columns:\n",
    "            train_df.drop(colname,axis=1,inplace=True)\n",
    "            \n",
    "        gp = train_df[selcols].groupby(groupby)[usecols].cumcount()        \n",
    "        train_df[colname] = gp.values\n",
    "    \n",
    "    elif aggregator == 'count':\n",
    "        colname = usecols[-1] + '_cnt_' + '_'.join(groupby)\n",
    "        if colname in train_df.columns:\n",
    "            train_df.drop(colname,axis=1,inplace=True)\n",
    "        gp = train_df[selcols].groupby(groupby)[usecols].count().reset_index().\\\n",
    "            rename(columns = {\n",
    "                usecols[-1] : colname\n",
    "            })\n",
    "        train_df = train_df.merge(gp, how='left', on=groupby)\n",
    "        \n",
    "    elif aggregator in ['var','mean']:\n",
    "        agg=np.var if aggregator == 'var' else np.mean\n",
    "        \n",
    "        colname = usecols[-1] + '_'+ str(aggregator) +'_' + '_'.join(groupby)\n",
    "        \n",
    "        if colname in train_df.columns:\n",
    "            train_df.drop(colname,axis=1, inplace=True)\n",
    "            \n",
    "        gp = train_df[selcols].groupby(groupby).agg(agg).reset_index().\\\n",
    "            rename(columns = {\n",
    "                usecols[-1] : colname\n",
    "            })\n",
    "        train_df = train_df.merge(gp, how='left', on=groupby)\n",
    "    \n",
    "    return train_df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feat_base             \n",
    "        - [v] channel_nunique_ip (X0)\n",
    "        - [v] app_nunique_channel (X6)\n",
    "        - [v] channel_cnt_ip_app (X10)\n",
    "        - [v] hour_nunique_day_ip (X2)\n",
    "        - [v] app_nunique_ip (X3)\n",
    "        - [v] app_nunique_ip_device_os (X8)\n",
    "        - [v] channel_cnt_ip_day_hour (ip_tcount)\n",
    "        - [v] app_cumcnt_ip_device_os (X1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0 : number of unique \"channel\" by ip\tchannel_nunique_ip\n",
      "X1: cumcount of app by (ip, device, os)\tapp_cumcnt_ip_device_os\n",
      "X2 : number of unique \"hour\" by (ip, day)\thour_nunique_ip_day\n",
      "X3 : number of unique \"app\" by ip\tapp_nunique_ip\n",
      "X6 : number of unique \"app\" by channel\tapp_nunique_channel\n",
      "X8 : number of unique \"app\" by (ip,device,os)\tapp_nunique_ip_device_os\n",
      "X10 : count by (ip,app)\tchannel_cnt_ip_app\n",
      "ip_tcount\tchannel_cnt_ip_day_hour\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "print('X0 : number of unique \"channel\" by ip',end='\\t')\n",
    "X0 = encode_agg_feature(trn_df,groupby=['ip'], selcols=['ip','channel'],aggregator='nunique')\n",
    "print(X0.name)\n",
    "trn_df[X0.name] = X0.values.astype('uint8') ; del X0;gc.collect()\n",
    "\n",
    "\n",
    "print('X1 : cumcount of app by (ip, device, os)',end='\\t')\n",
    "X1 = encode_agg_feature(trn_df, selcols=['ip','device','os','app'], groupby=['ip','device','os'], aggregator='cumcount')\n",
    "print(X1.name)\n",
    "trn_df[X1.name] = X1.values.astype('uint16'); del X1;gc.collect()\n",
    "\n",
    "\n",
    "print('X2 : number of unique \"hour\" by (ip, day)',end='\\t')\n",
    "X2 = encode_agg_feature(trn_df,selcols=['hour','ip','day'], groupby=['ip','day'], aggregator='nunique')\n",
    "print(X2.name)\n",
    "trn_df[X2.name] = X2.values.astype('uint8'); del X2;gc.collect()\n",
    "\n",
    "\n",
    "print('X3 : number of unique \"app\" by ip', end='\\t')\n",
    "X3 = encode_agg_feature(trn_df,selcols=['app', 'ip'], groupby=['ip'])\n",
    "print(X3.name)\n",
    "trn_df[X3.name] = X3.values.astype('uint8'); del X3; gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "print('X6 : number of unique \"app\" by channel',end='\\t')\n",
    "X6 = encode_agg_feature(trn_df,selcols=['app', 'channel'], groupby=['channel'])\n",
    "print(X6.name)\n",
    "trn_df[X6.name] = X6.values.astype('uint8'); del X6; gc.collect()\n",
    "\n",
    "\n",
    "print('X8 : number of unique \"app\" by (ip,device,os)',end='\\t')\n",
    "X8 = encode_agg_feature(trn_df,selcols=['app', 'ip','device','os'], groupby=['ip','device','os'])\n",
    "print(X8.name)\n",
    "trn_df[X8.name] = X8.values.astype('uint8'); del X8;gc.collect()\n",
    "\n",
    "### count ####\n",
    "print('X10: count by (ip,app)', end='\\t')\n",
    "X10 = encode_agg_feature(trn_df,selcols=['ip','app','channel'],groupby=['ip','app'],aggregator='count')\n",
    "print(X10.name)\n",
    "trn_df[X10.name]= X10.values.astype('uint16'); del X10;gc.collect()\n",
    "\n",
    "\n",
    "print('ip_tcount',end='\\t')\n",
    "ip_tcount = encode_agg_feature(trn_df,selcols=['ip','day','hour','channel'], groupby=['ip','day','hour'],aggregator='count')\n",
    "print(ip_tcount.name)\n",
    "trn_df[ip_tcount.name]= ip_tcount.values.astype('uint16'); del ip_tcount;gc.collect()\n",
    "\n",
    "\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importanta feature \n",
    "\n",
    "#### next click\n",
    "\n",
    "- next click time by ('ip','app','os','device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next click time by(ip,app,os,device)...\n",
      "shift 1...\n",
      "next_click_dt added\n",
      "gc...\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "print('next click time by(ip,app,os,device)...')\n",
    "gp = trn_df.groupby(['ip','app','os','device'])\n",
    "print('shift 1...')\n",
    "\n",
    "trn_df['shift_1'] = gp.click_time.shift(-1)\n",
    "cst = pytz.timezone('Asia/Shanghai')\n",
    "trn_df['shift_1'] = pd.to_datetime(trn_df['shift_1']).dt.tz_localize(pytz.utc).dt.tz_convert(cst) \n",
    "trn_df['next_click_dt'] = ((trn_df.shift_1 - trn_df.click_time) / np.timedelta64(1,'s')).fillna(50000).astype('uint16')\n",
    "print('next_click_dt added')\n",
    "\n",
    "print('gc...')\n",
    "trn_df.drop(['shift_1'],axis=1,inplace=True)\n",
    "gc.collect()\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.HDFStore('../input/feat/feat3_partial3.h5')\n",
    "store['trn_df'] = trn_df\n",
    "store.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ec3d082176ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHDFStore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../input/feat/feat4_trn_day8_val_day9.h5'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstore\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtrn_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trn_df'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('../input/feat/feat4_trn_day8_val_day9.h5') as store:\n",
    "    trn_df = store['trn_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_tst = 18790469\n",
    "len_trn = 143984060 - 18790469"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean encode ON TRAINNING ONLY NOT ON TEST ###\n",
    "- app_mean_target\n",
    "- channel_mean_target\n",
    "- device_mean_target \t\n",
    "- ip_mean_target\n",
    "\n",
    "- (ip,app,device,os) mean target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = trn_df.iloc[len_trn:,]\n",
    "# trn_df  = trn_df.iloc[:len_trn,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = 0\n",
    "if debug:\n",
    "    len_tst = 10000\n",
    "    len_trn = 10000\n",
    "else:\n",
    "    len_tst = 18790469\n",
    "    len_trn = 143984060 - 18790469\n",
    "test_df = trn_df.iloc[len_trn:,]\n",
    "trn_df = trn_df.iloc[:len_trn,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_df shape : (125193591, 19)\n",
      "test_df shape: (18790469, 19)\n"
     ]
    }
   ],
   "source": [
    "print('trn_df shape :',trn_df.shape)\n",
    "print('test_df shape:',test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy trn_df to make new features\n",
      "create new cols\n",
      "fold:0 mean encoding...\n",
      "\t['ip', 'app', 'os', 'device']\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\__main__.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ip\tapp\tchannel\tdevice\t\n",
      "fold:1 mean encoding...\n",
      "\t['ip', 'app', 'os', 'device']\tip\tapp\tchannel\tdevice\t\n",
      "fold:2 mean encoding...\n",
      "\t['ip', 'app', 'os', 'device']\tip\tapp\tchannel\tdevice\t\n",
      "fold:3 mean encoding...\n",
      "\t['ip', 'app', 'os', 'device']\tip\tapp\tchannel\tdevice\t\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "print('copy trn_df to make new features')\n",
    "train_new = trn_df.copy()\n",
    "\n",
    "print('create new cols')\n",
    "cols = [['ip','app','os','device'],'ip','app','channel','device','os']\n",
    "for col in cols :\n",
    "    if isinstance(col,list):\n",
    "        col_str = '_'.join(col)\n",
    "    else:\n",
    "        col_str = col\n",
    "    train_new[col_str + '_mean_target'] = 0\n",
    "\n",
    "print('StratifiedKFold...')\n",
    "y_tr = trn_df.is_attributed.values.astype(np.int8) # target \n",
    "skf = StratifiedKFold(4, random_state=0)\n",
    "skf.get_n_splits(X=trn_df,y=y_tr)\n",
    "\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(skf.split(train_new,y_tr)):\n",
    "    \n",
    "    ## generate features \n",
    "    \n",
    "    X_tr ,X_val = trn_df.iloc[tr_idx], trn_df.iloc[val_idx]\n",
    "    \n",
    "    print('fold:{} mean encoding...'.format(fold),end='\\n\\t')\n",
    "#     print('tr_idx:{}'.format(tr_idx))\n",
    "    for col in cols:        \n",
    "        print(col,end='\\t')\n",
    "        if isinstance(col,str):\n",
    "            means = X_val[col].map(X_tr.groupby(col).is_attributed.mean()) ## map mean encoding in X_tr to X_val\n",
    "            col_str = col\n",
    "            \n",
    "        elif isinstance(col,list):\n",
    "            col_str = '_'.join(col)\n",
    "            gp = X_tr.groupby(col).is_attributed.mean().reset_index().rename(columns={'is_attributed':col_str+'_mean_target'})\n",
    "            means = X_val[col].merge(gp,how='left',on=col)[col_str+'_mean_target']\n",
    "            \n",
    "        X_val[col_str + '_mean_target'] = means.astype('float16')\n",
    "        del means;gc.collect()\n",
    "        \n",
    "        \n",
    "        \n",
    "    train_new.iloc[val_idx] = X_val\n",
    "    print('')    \n",
    "    del X_tr,X_val;gc.collect()\n",
    "            \n",
    "prior = trn_df.is_attributed.mean()\n",
    "\n",
    "col_used = [ '_'.join(col) + '_mean_target' if isinstance(col,list) else col for col in cols]\n",
    "train_new[col_used] = train_new[col_used].fillna(prior)\n",
    "\n",
    "trn_df = train_new\n",
    "del train_new;gc.collect()\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 125193591 entries, 59709852 to 184903442\n",
      "Data columns (total 24 columns):\n",
      "app                             uint16\n",
      "channel                         uint16\n",
      "click_id                        float64\n",
      "click_time                      datetime64[ns, Asia/Shanghai]\n",
      "day                             uint8\n",
      "device                          uint16\n",
      "hour                            uint8\n",
      "ip                              uint32\n",
      "is_attributed                   float64\n",
      "os                              uint16\n",
      "channel_nunique_ip              uint8\n",
      "app_cumcnt_ip_device_os         uint16\n",
      "hour_nunique_ip_day             uint8\n",
      "app_nunique_ip                  uint8\n",
      "app_nunique_channel             uint8\n",
      "app_nunique_ip_device_os        uint8\n",
      "channel_cnt_ip_app              uint16\n",
      "channel_cnt_ip_day_hour         uint16\n",
      "next_click_dt                   uint16\n",
      "ip_app_os_device_mean_target    float16\n",
      "ip_mean_target                  float16\n",
      "app_mean_target                 float16\n",
      "channel_mean_target             float16\n",
      "device_mean_target              float16\n",
      "dtypes: datetime64[ns, Asia/Shanghai](1), float16(5), float64(2), uint16(8), uint32(1), uint8(7)\n",
      "memory usage: 8.0 GB\n"
     ]
    }
   ],
   "source": [
    "trn_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean encode on TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_mean col:['ip', 'app', 'os', 'device']...\n",
      "target_mean col:ip...\n",
      "target_mean col:app...\n",
      "target_mean col:device...\n",
      "target_mean col:channel...\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "cols = [['ip','app','os','device'],'ip','app','device','channel']\n",
    "\n",
    "selcols = ['ip','app','os','device','channel','is_attributed']\n",
    "\n",
    "for col in cols:\n",
    "    print('target_mean col:{}...'.format(col))\n",
    "    gp = trn_df[selcols].groupby(col)\n",
    "    if isinstance(col,list):\n",
    "        col_str = '_'.join(col)\n",
    "        gp = gp.is_attributed.mean().reset_index().rename(columns={'is_attributed':col_str+'_mean_target'})\n",
    "        means = test_df.merge(gp,how='left',on=col)[col_str+'_mean_target'].astype('float16')\n",
    "    else:\n",
    "        col_str = col\n",
    "        means = test_df[col].map(gp.is_attributed.mean()).astype('float16')\n",
    "        \n",
    "    test_df[col_str +'_mean_target'] = means\n",
    "    del means,gp;gc.collect()\n",
    "    \n",
    "prior = trn_df.is_attributed.mean()\n",
    "\n",
    "\n",
    "col_used = [ '_'.join(col) + '_mean_target' if isinstance(col,list) else col for col in cols]\n",
    "test_df[col_used].fillna(prior)\n",
    "\n",
    "gc.collect()\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18790469, 24)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18790469 entries, 0 to 18790468\n",
      "Data columns (total 24 columns):\n",
      "app                             uint16\n",
      "channel                         uint16\n",
      "click_id                        float64\n",
      "click_time                      datetime64[ns, Asia/Shanghai]\n",
      "day                             uint8\n",
      "device                          uint16\n",
      "hour                            uint8\n",
      "ip                              uint32\n",
      "is_attributed                   float64\n",
      "os                              uint16\n",
      "channel_nunique_ip              uint8\n",
      "app_cumcnt_ip_device_os         uint16\n",
      "hour_nunique_ip_day             uint8\n",
      "app_nunique_ip                  uint8\n",
      "app_nunique_channel             uint8\n",
      "app_nunique_ip_device_os        uint8\n",
      "channel_cnt_ip_app              uint16\n",
      "channel_cnt_ip_day_hour         uint16\n",
      "next_click_dt                   uint16\n",
      "ip_app_os_device_mean_target    float16\n",
      "ip_mean_target                  float16\n",
      "app_mean_target                 float16\n",
      "device_mean_target              float16\n",
      "channel_mean_target             float16\n",
      "dtypes: datetime64[ns, Asia/Shanghai](1), float16(5), float64(2), uint16(8), uint32(1), uint8(7)\n",
      "memory usage: 1.2 GB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## day8 train_sets\n",
    "train_df = trn_df[trn_df.day==8]\n",
    "## day9 valid sets \n",
    "val_df = trn_df[trn_df.day==9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (62360949, 24)\n",
      "valid shape:  (62832642, 24)\n",
      "test shape :  (18790469, 24)\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape: \", train_df.shape)\n",
    "print(\"valid shape: \", val_df.shape)\n",
    "print(\"test shape : \", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../feat4_trn_day8_val_day9\n"
     ]
    }
   ],
   "source": [
    "trn_day = 'day8'\n",
    "val_day = 'day9'\n",
    "print('../../feat4_trn_{}_val_{}'.format(trn_day,val_day))\n",
    "store = pd.HDFStore('../input/feat/feat4_trn_{}_val_{}.h5'.format(trn_day,val_day))\n",
    "store['train_df'] = train_df\n",
    "store['valid_df'] = val_df\n",
    "store['test_df'] = test_df\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore('../input/feat/feat4_trn_day8_val_day9.h5') as store:\n",
    "    train_df = store['train_df']\n",
    "    val_df   = store['valid_df']\n",
    "    test_df  = store['test_df']"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
