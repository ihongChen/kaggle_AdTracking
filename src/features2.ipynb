{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script add \n",
    "- mean encoding by ip,os,device,os, app,channel\n",
    "\n",
    "compare to features1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "import gc,time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/test_df', '/train_df']\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('../input/raw_data.h5') as store:\n",
    "    print(store.keys())\n",
    "    test_df = store['test_df']\n",
    "    train_df = store['train_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = 0\n",
    "if debug:\n",
    "    nrows = 100000\n",
    "    nchunk = 400000\n",
    "    val_size = 25000\n",
    "    frm = nrows - 75000\n",
    "    to = frm + nchunk\n",
    "    \n",
    "    test_size = 50000\n",
    "    test_df = test_df.iloc[:test_size,:]\n",
    "else:\n",
    "    nrows=184903891-1\n",
    "    nchunk=40000000\n",
    "\n",
    "    val_size=2500000\n",
    "    frm=nrows-75000000\n",
    "    to = frm + nchunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df = train_df.iloc[frm:to,:]\n",
    "len_trn = len(trn_df)\n",
    "trn_df = trn_df.append(test_df)\n",
    "\n",
    "# del train_df;test_df;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_df :(58790469, 10)\n"
     ]
    }
   ],
   "source": [
    "print('trn_df :{}'.format(trn_df.shape)) # \n",
    "# print('test_df:{}'.format(test_df.shape))\n",
    "del test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_agg_feature(train_df, selcols, groupby, aggregator = 'nunique'):\n",
    "    usecols = [e for e in selcols if e not in  groupby]    \n",
    "    \n",
    "    if aggregator == 'nunique':  \n",
    "        colname= usecols[-1] + '_nunique_' + '_'.join(groupby)\n",
    "        if colname in train_df.columns:\n",
    "            train_df.drop(colname,axis=1,inplace=True)\n",
    "            \n",
    "        gp = train_df[selcols].groupby(groupby)[usecols].nunique().reset_index().\\\n",
    "            rename(columns = {\n",
    "                usecols[-1] : usecols[-1] + '_nunique_' + '_'.join(groupby)\n",
    "            })\n",
    "        train_df = train_df.merge(gp, how='left', on=groupby)\n",
    "\n",
    "    elif aggregator == 'cumcount':\n",
    "        colname = usecols[-1] + '_cumcnt_' + '_'.join(groupby)\n",
    "        if colname in train_df.columns:\n",
    "            train_df.drop(colname,axis=1,inplace=True)\n",
    "            \n",
    "        gp = train_df[selcols].groupby(groupby)[usecols].cumcount()        \n",
    "        train_df[colname] = gp.values\n",
    "    \n",
    "    elif aggregator == 'count':\n",
    "        colname = usecols[-1] + '_cnt_' + '_'.join(groupby)\n",
    "        if colname in train_df.columns:\n",
    "            train_df.drop(colname,axis=1,inplace=True)\n",
    "        gp = train_df[selcols].groupby(groupby)[usecols].count().reset_index().\\\n",
    "            rename(columns = {\n",
    "                usecols[-1] : colname\n",
    "            })\n",
    "        train_df = train_df.merge(gp, how='left', on=groupby)\n",
    "        \n",
    "    elif aggregator in ['var','mean']:\n",
    "        agg=np.var if aggregator == 'var' else np.mean\n",
    "        \n",
    "        colname = usecols[-1] + '_'+ str(aggregator) +'_' + '_'.join(groupby)\n",
    "        \n",
    "        if colname in train_df.columns:\n",
    "            train_df.drop(colname,axis=1, inplace=True)\n",
    "            \n",
    "        gp = train_df[selcols].groupby(groupby).agg(agg).reset_index().\\\n",
    "            rename(columns = {\n",
    "                usecols[-1] : colname\n",
    "            })\n",
    "        train_df = train_df.merge(gp, how='left', on=groupby)\n",
    "    \n",
    "    return train_df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feat_base\n",
    "\n",
    "- channel cnt by (ip,day,hour)\n",
    "- channel cnt by (ip,app)\n",
    "- channel nunique by ip\n",
    "- device nunique by ip\n",
    "- app nunique by ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature1 : number of unique \"channel\" by ip\tchannel_nunique_ip\n",
      "feature2 : cumcount of \"app\" by (ip,device,os)\tapp_cumcnt_ip_device_os\n",
      "feature3 : number of unique \"hour\" by (ip, day)\thour_nunique_ip_day\n",
      "feature4 : number of unique \"app\" by ip\tapp_nunique_ip\n",
      "feature5 : number of unique \"app\" by (ip,os)\tapp_nunique_ip_os\n",
      "feature6 : number of unique \"device\" by ip\tdevice_nunique_ip\n",
      "feature7 : number of unique \"app\" by channel\tapp_nunique_channel\n",
      "feature8 : cumcount of \"os\" by ip \tos_cumcnt_ip\n",
      "feature9 : number of unique \"app\" by (ip,device,os)\tapp_nunique_ip_device_os\n",
      "feature 10 : count by (ip,day,hour)\tchannel_cnt_ip_day_hour\n",
      "feature 11 : count by (ip,app)\tchannel_cnt_ip_app\n",
      "feature 12 : count by (ip,app,os)\tchannel_cnt_ip_app_os\n",
      "feature 13: var of hour by (ip,day,channel)\thour_var_ip_day_channel\n",
      "feature 14: var of hour by (ip,app,os)\thour_var_ip_app_os\n",
      "feature 15: var of day by (ip,app,channel)\tday_var_ip_app_channel\n",
      "feature 16: mean of hour by (ip,app,channel)\thour_mean_ip_app_channel\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('feature1 : number of unique \"channel\" by ip',end='\\t')\n",
    "f1 = encode_agg_feature(trn_df,groupby=['ip'], selcols=['ip','channel'],aggregator='nunique')\n",
    "print(f1.name)\n",
    "\n",
    "print('feature2 : cumcount of \"app\" by (ip,device,os)',end='\\t')\n",
    "f2 = encode_agg_feature(trn_df,selcols=['app','ip','device','os'], groupby=['ip','device','os'], aggregator='cumcount')\n",
    "print(f2.name)\n",
    "\n",
    "print('feature3 : number of unique \"hour\" by (ip, day)',end='\\t')\n",
    "f3 = encode_agg_feature(trn_df,selcols=['hour','ip','day'], groupby=['ip','day'], aggregator='nunique')\n",
    "print(f3.name)\n",
    "\n",
    "print('feature4 : number of unique \"app\" by ip', end='\\t')\n",
    "f4 = encode_agg_feature(trn_df,selcols=['app', 'ip'], groupby=['ip'])\n",
    "print(f4.name)\n",
    "\n",
    "print('feature5 : number of unique \"app\" by (ip,os)',end='\\t')\n",
    "f5 = encode_agg_feature(trn_df,selcols=['app', 'ip', 'os'], groupby=['ip','os'])\n",
    "print(f5.name)\n",
    "\n",
    "print('feature6 : number of unique \"device\" by ip',end='\\t')\n",
    "f6 = encode_agg_feature(trn_df,selcols=['device', 'ip'], groupby=['ip'])\n",
    "print(f6.name)\n",
    "\n",
    "print('feature7 : number of unique \"app\" by channel',end='\\t')\n",
    "f7 = encode_agg_feature(trn_df,selcols=['app', 'channel'], groupby=['channel'])\n",
    "print(f7.name)\n",
    "\n",
    "print('feature8 : cumcount of \"os\" by ip ',end='\\t')\n",
    "f8 = encode_agg_feature(trn_df,selcols=['os', 'ip'], groupby=['ip'], aggregator='cumcount')\n",
    "print(f8.name)\n",
    "\n",
    "print('feature9 : number of unique \"app\" by (ip,device,os)',end='\\t')\n",
    "f9 = encode_agg_feature(trn_df,selcols=['app', 'ip','device','os'], groupby=['ip','device','os'])\n",
    "print(f9.name)\n",
    "\n",
    "#### count #####\n",
    "print('feature 10 : count by (ip,day,hour)',end='\\t')\n",
    "f10 = encode_agg_feature(trn_df,selcols=['ip','day','hour','channel'],groupby=['ip','day','hour'],aggregator='count')\n",
    "print(f10.name)\n",
    "\n",
    "print('feature 11 : count by (ip,app)', end='\\t')\n",
    "f11 = encode_agg_feature(trn_df,selcols=['ip','app','channel'],groupby=['ip','app'],aggregator='count')\n",
    "print(f11.name)\n",
    "\n",
    "print('feature 12 : count by (ip,app,os)',end='\\t')\n",
    "f12 = encode_agg_feature(trn_df,selcols=['ip','app','channel','os'],groupby=['ip','app','os'],aggregator='count')\n",
    "print(f12.name)\n",
    "\n",
    "### mean,var ####\n",
    "print('feature 13: var of hour by (ip,day,channel)',end='\\t')\n",
    "f13 = encode_agg_feature(trn_df,selcols=['ip','day','channel','hour'],\n",
    "                         groupby=['ip','day','channel'],\n",
    "                         aggregator='var'                    \n",
    "                        )\n",
    "print(f13.name)\n",
    "\n",
    "print('feature 14: var of hour by (ip,app,os)', end='\\t')\n",
    "f14 =encode_agg_feature(trn_df,selcols=['ip','app','os','hour'], groupby=['ip','app','os'], aggregator='var')\n",
    "print(f14.name)\n",
    "\n",
    "print('feature 15: var of day by (ip,app,channel)',end='\\t')\n",
    "f15 = encode_agg_feature(trn_df,selcols=['ip','app','channel','day'],groupby=['ip','app','channel'], aggregator='var')\n",
    "print(f15.name)\n",
    "\n",
    "print('feature 16: mean of hour by (ip,app,channel)', end='\\t')\n",
    "f16 = encode_agg_feature(trn_df,selcols=['ip','app','channel','hour'],groupby=['ip','app','channel'],aggregator='mean')\n",
    "print(f16.name)\n",
    "\n",
    "\n",
    "trn_df[f1.name] = f1.values.astype('uint8') ; del f1;gc.collect()\n",
    "trn_df[f2.name] = f2.values.astype('uint16'); del f2;gc.collect()\n",
    "trn_df[f3.name] = f3.values.astype('uint8'); del f3;gc.collect()\n",
    "trn_df[f4.name] = f4.values.astype('uint8'); del f4; gc.collect()\n",
    "trn_df[f5.name] = f5.values.astype('uint8'); del f5; gc.collect()\n",
    "trn_df[f6.name] = f6.values.astype('uint8'); del f6; gc.collect()\n",
    "trn_df[f7.name] = f7.values.astype('uint8'); del f7; gc.collect()\n",
    "trn_df[f8.name] = f8.values.astype('uint16'); del f8;gc.collect()\n",
    "trn_df[f9.name] = f9.values.astype('uint8'); del f9;gc.collect()\n",
    "trn_df[f10.name]= f10.values.astype('uint16'); del f10;gc.collect()\n",
    "trn_df[f11.name]= f11.values.astype('uint16'); del f11;gc.collect()\n",
    "trn_df[f12.name] = f12.values.astype('uint16'); del f12;gc.collect()\n",
    "\n",
    "trn_df[f13.name] = f13.values.astype('float16'); del f13;gc.collect()\n",
    "trn_df[f14.name] = f14.values.astype('float16'); del f14;gc.collect()\n",
    "trn_df[f15.name] = f15.values.astype('float16'); del f15; gc.collect()\n",
    "trn_df[f16.name] = f16.values.astype('float16'); del f16;gc.collect()\n",
    "\n",
    "# del f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f11,f12,f13,f14,f15,f16;gc.collect()\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importanta feature \n",
    "\n",
    "#### next click\n",
    "\n",
    "- next click time by ('ip','app','os','device')\n",
    "- next click time 2 by ...\n",
    "- cnt by next click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next click time by(ip,app,os,device)...\n",
      "shift 1...\n",
      "shift 2...\n",
      "timedelta to uint16...\n",
      "cnt by next click...\n",
      "gc...\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "print('next click time by(ip,app,os,device)...')\n",
    "gp = trn_df.groupby(['ip','app','os','device'])\n",
    "print('shift 1...')\n",
    "trn_df['shift_1'] = gp.click_time.shift(-1)\n",
    "print('shift 2...')\n",
    "trn_df['shift_2'] = gp.click_time.shift(-2)\n",
    "print('timedelta to uint16...')\n",
    "trn_df['next_click_dt'] = ((trn_df.shift_1 - trn_df.click_time) / np.timedelta64(1,'s')).fillna(50000).astype('uint16')\n",
    "trn_df['next_click_dt2'] = ((trn_df.shift_2 - trn_df.click_time) / np.timedelta64(1,'s')).fillna(50000).astype('uint16')\n",
    "\n",
    "print('cnt by next click...')\n",
    "\n",
    "nextclick_cnt = trn_df.next_click_dt.value_counts().reset_index().\\\n",
    "    rename(columns={'index':'next_click_dt','next_click_dt':'next_click_dt_cnt'}).astype('uint32')\n",
    "trn_df = trn_df.merge(nextclick_cnt,how='left')\n",
    "\n",
    "print('gc...')\n",
    "trn_df.drop(['shift_1','shift_2'],axis=1,inplace=True)\n",
    "del nextclick_cnt; gc.collect()\n",
    "print('complete')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean encode ON TRAINNING ONLY NOT ON TEST ###\n",
    "- ip mean target\n",
    "- app mean target \n",
    "- channel mean target \n",
    "- os mean target\n",
    "- device mean target\n",
    "\n",
    "NEED DATA COPY ---> may memory consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = trn_df.iloc[len_trn:,]\n",
    "trn_df  = trn_df.iloc[:len_trn,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy trn_df to make new features\n",
      "fold:0 mean encoding...\n",
      "\tip\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel\\__main__.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app\tchannel\tos\tdevice\t\n",
      "fold:1 mean encoding...\n",
      "\tip\tapp\tchannel\tos\tdevice\t\n",
      "fold:2 mean encoding...\n",
      "\tip\tapp\tchannel\tos\tdevice\t\n",
      "fold:3 mean encoding...\n",
      "\tip\tapp\tchannel\tos\tdevice\t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "print('copy trn_df to make new features')\n",
    "train_new = trn_df.copy()\n",
    "\n",
    "cols = ['ip','app','channel','os','device']\n",
    "for col in cols :\n",
    "    train_new[col+'_mean_target'] = 0\n",
    "    \n",
    "y_tr = trn_df.is_attributed.values.astype(np.int8) # target \n",
    "skf = StratifiedKFold(4, random_state=0)\n",
    "skf.get_n_splits(X=trn_df,y=y_tr)\n",
    "\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(skf.split(train_new,y_tr)):\n",
    "    \n",
    "    ## generate features \n",
    "    \n",
    "    X_tr ,X_val = trn_df.iloc[tr_idx], trn_df.iloc[val_idx]\n",
    "    \n",
    "    print('fold:{} mean encoding...'.format(fold),end='\\n\\t')\n",
    "#     print('tr_idx:{}'.format(tr_idx))\n",
    "    for col in cols:        \n",
    "        print(col,end='\\t')\n",
    "        means = X_val[col].map(X_tr.groupby(col).is_attributed.mean()) ## map mean encoding in X_tr to X_val\n",
    "        X_val[col + '_mean_target'] = means.astype('float16')\n",
    "        \n",
    "    train_new.iloc[val_idx] = X_val\n",
    "    print('')    \n",
    "    del X_tr,X_val;gc.collect()\n",
    "            \n",
    "prior = trn_df.is_attributed.mean()\n",
    "train_new[[col+'_mean_target' for col in cols]] = train_new[[col+'_mean_target' for col in cols]].fillna(prior)\n",
    "\n",
    "trn_df = train_new\n",
    "del train_new;gc.collect()\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40000000 entries, 0 to 39999999\n",
      "Data columns (total 34 columns):\n",
      "app                         uint16\n",
      "channel                     uint16\n",
      "click_id                    float64\n",
      "click_time                  datetime64[ns]\n",
      "day                         uint8\n",
      "device                      uint16\n",
      "hour                        uint8\n",
      "ip                          uint32\n",
      "is_attributed               float64\n",
      "os                          uint16\n",
      "app_cumcnt_ip_device_os     uint16\n",
      "os_cumcnt_ip                uint16\n",
      "channel_nunique_ip          uint8\n",
      "hour_nunique_ip_day         uint8\n",
      "app_nunique_ip              uint8\n",
      "app_nunique_ip_os           uint8\n",
      "device_nunique_ip           uint8\n",
      "app_nunique_channel         uint8\n",
      "app_nunique_ip_device_os    uint8\n",
      "channel_cnt_ip_day_hour     uint16\n",
      "channel_cnt_ip_app          uint16\n",
      "channel_cnt_ip_app_os       uint16\n",
      "hour_var_ip_day_channel     float16\n",
      "hour_var_ip_app_os          float16\n",
      "day_var_ip_app_channel      float16\n",
      "hour_mean_ip_app_channel    float16\n",
      "next_click_dt               uint16\n",
      "next_click_dt2              uint16\n",
      "next_click_dt_cnt           uint32\n",
      "ip_mean_target              float16\n",
      "app_mean_target             float16\n",
      "channel_mean_target         float16\n",
      "os_mean_target              float16\n",
      "device_mean_target          float16\n",
      "dtypes: datetime64[ns](1), float16(9), float64(2), uint16(11), uint32(2), uint8(9)\n",
      "memory usage: 3.3 GB\n"
     ]
    }
   ],
   "source": [
    "trn_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean encode on TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_mean col:ip...\n",
      "target_mean col:os...\n",
      "target_mean col:app...\n",
      "target_mean col:device...\n",
      "target_mean col:channel...\n"
     ]
    }
   ],
   "source": [
    "cols = ['ip','os','app','device','channel']\n",
    "selcols = cols + ['is_attributed']\n",
    "\n",
    "for col in cols:\n",
    "    print('target_mean col:{}...'.format(col))\n",
    "    gp = trn_df[selcols].groupby(col)\n",
    "    test_df[col+'_mean_target'] = test_df[col].map(gp.is_attributed.mean()) \n",
    "    \n",
    "prior = trn_df.is_attributed.mean()\n",
    "test_df[[col+'_mean_target' for col in cols]] = test_df[[col+'_mean_target' for col in cols]].fillna(prior)\n",
    "gc.collect()\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18790469, 34)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18790469 entries, 40000000 to 58790468\n",
      "Data columns (total 34 columns):\n",
      "app                         uint16\n",
      "channel                     uint16\n",
      "click_id                    float64\n",
      "click_time                  datetime64[ns]\n",
      "day                         uint8\n",
      "device                      uint16\n",
      "hour                        uint8\n",
      "ip                          uint32\n",
      "is_attributed               float64\n",
      "os                          uint16\n",
      "app_cumcnt_ip_device_os     uint16\n",
      "os_cumcnt_ip                uint16\n",
      "channel_nunique_ip          uint8\n",
      "hour_nunique_ip_day         uint8\n",
      "app_nunique_ip              uint8\n",
      "app_nunique_ip_os           uint8\n",
      "device_nunique_ip           uint8\n",
      "app_nunique_channel         uint8\n",
      "app_nunique_ip_device_os    uint8\n",
      "channel_cnt_ip_day_hour     uint16\n",
      "channel_cnt_ip_app          uint16\n",
      "channel_cnt_ip_app_os       uint16\n",
      "hour_var_ip_day_channel     float16\n",
      "hour_var_ip_app_os          float16\n",
      "day_var_ip_app_channel      float16\n",
      "hour_mean_ip_app_channel    float16\n",
      "next_click_dt               uint16\n",
      "next_click_dt2              uint16\n",
      "next_click_dt_cnt           uint32\n",
      "ip_mean_target              float64\n",
      "os_mean_target              float64\n",
      "app_mean_target             float64\n",
      "device_mean_target          float64\n",
      "channel_mean_target         float64\n",
      "dtypes: datetime64[ns](1), float16(4), float64(7), uint16(11), uint32(2), uint8(9)\n",
      "memory usage: 2.1 GB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37500000, 34)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (37500000, 34)\n",
      "valid shape:  (2500000, 34)\n",
      "test shape :  (18790469, 34)\n"
     ]
    }
   ],
   "source": [
    "val_df = trn_df[(len_trn-val_size):len_trn]\n",
    "train_df = trn_df[:(len_trn-val_size)]\n",
    "\n",
    "print(\"train shape: \", train_df.shape)\n",
    "print(\"valid shape: \", val_df.shape)\n",
    "print(\"test shape : \", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../feat2_109903890_149903890\n"
     ]
    }
   ],
   "source": [
    "print('../../feat2_{}_{}'.format(frm,to))\n",
    "store = pd.HDFStore('../input/feat/feat2_{}_{}.h5'.format(frm,to))\n",
    "store['train_df'] = train_df\n",
    "store['valid_df'] = val_df\n",
    "store['test_df'] = test_df\n",
    "store.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
